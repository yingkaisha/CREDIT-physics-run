{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "efa08066-4289-4781-902c-7e83e244857d",
   "metadata": {},
   "source": [
    "# Pre-process ERA5 pressure level data for CREDIT\n",
    "\n",
    "This notebook provides methods on gathering ERA5 pressure level data from NCAR/RDA and ARCO-ERA5. The RDA data requires internal access of the glade file system at NCAR.\n",
    "\n",
    "## Data preparation\n",
    "\n",
    "* **Pressure-level analysis (RDA)**\n",
    "    * geopotential, u_component_of_wind, v_component_of_wind, temperature, specific_humidity\n",
    "* **Single-level analysis (RDA)**\n",
    "    * surface_pressure, mean_sea_level_pressure\n",
    "    * sea_surface_temperature, skin_temperature, 2m_temperature,\n",
    "    * 10m_u_component_of_wind, 10m_v_component_of_wind, total_cloud_cover\n",
    "* **Single-level forecasts (ARCO)**\n",
    "    * total_precipitation, evaporation\n",
    "    * top_net_solar_radiation, top_net_thermal_radiation\n",
    "    * surface_net_solar_radiation, surface_net_thermal_radiation, surface_latent_heat_flux, surface_sensible_heat_flux\n",
    "\n",
    "**References**\n",
    "\n",
    "* NCAR/RDA\n",
    "    * [ERA5 Reanalysis (0.25 Degree Latitude-Longitude Grid)](https://rda.ucar.edu/datasets/d633000/)\n",
    "    * glade storage: `/glade/campaign/collections/rda/data/d633000/`\n",
    "* ARCO-ERA5\n",
    "    * [Google Cloud storage](https://console.cloud.google.com/storage/browser/gcp-public-data-arco-era5)\n",
    "    * [Project page at GitHub](https://github.com/google-research/arco-era5)\n",
    "    * Complete hourly file: `gs://gcp-public-data-arco-era5/ar/full_37-1h-0p25deg-chunk-1.zarr-v3`\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "70332162-6c47-4172-a003-326059f10045",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import yaml\n",
    "import dask\n",
    "import zarr\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "import pandas as pd\n",
    "from glob import glob\n",
    "from dask.utils import SerializableLock\n",
    "\n",
    "import calendar\n",
    "from datetime import datetime, timedelta\n",
    "from dateutil.relativedelta import relativedelta\n",
    "\n",
    "sys.path.insert(0, os.path.realpath('../libs/'))\n",
    "import verif_utils as vu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4f217f9a-f8a5-4798-b055-c26c6f0d7fe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import multiprocessing\n",
    "# from dask.distributed import Client\n",
    "# from dask_jobqueue import PBSCluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "aa740e32-0024-4dec-b2c9-ce7c7f92f925",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0068fbd7-18c4-496a-a1f7-c63f26c59544",
   "metadata": {},
   "source": [
    "## Upper-air variables"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e804cc7b-5116-4492-b772-03dec0ae2f34",
   "metadata": {},
   "source": [
    "**NCAR/RDA**\n",
    "\n",
    "An example of file listing at `/glade/campaign/collections/rda/data/d633000/e5.oper.an.pl/197901`\n",
    "```\n",
    "e5.oper.an.pl.128_060_pv.ll025sc.1979010100_1979010123.nc    \n",
    "e5.oper.an.pl.128_132_v.ll025uv.1979010100_1979010123.nc   \n",
    "e5.oper.an.pl.128_203_o3.ll025sc.1979010100_1979010123.nc\n",
    "e5.oper.an.pl.128_075_crwc.ll025sc.1979010100_1979010123.nc  \n",
    "e5.oper.an.pl.128_133_q.ll025sc.1979010100_1979010123.nc\n",
    "e5.oper.an.pl.128_246_clwc.ll025sc.1979010100_1979010123.nc\n",
    "e5.oper.an.pl.128_076_cswc.ll025sc.1979010100_1979010123.nc  \n",
    "e5.oper.an.pl.128_135_w.ll025sc.1979010100_1979010123.nc   \n",
    "e5.oper.an.pl.128_247_ciwc.ll025sc.1979010100_1979010123.nc\n",
    "e5.oper.an.pl.128_129_z.ll025sc.1979010100_1979010123.nc     \n",
    "e5.oper.an.pl.128_138_vo.ll025sc.1979010100_1979010123.nc  \n",
    "e5.oper.an.pl.128_248_cc.ll025sc.1979010100_1979010123.nc\n",
    "e5.oper.an.pl.128_130_t.ll025sc.1979010100_1979010123.nc     \n",
    "e5.oper.an.pl.128_155_d.ll025sc.1979010100_1979010123.nc\n",
    "e5.oper.an.pl.128_131_u.ll025uv.1979010100_1979010123.nc     \n",
    "e5.oper.an.pl.128_157_r.ll025sc.1979010100_1979010123.nc\n",
    "```\n",
    "\n",
    "* crwc: specific rain water content\n",
    "* cswc: Specific snow water content\n",
    "* clwc: Specific cloud liquid water content\n",
    "* ciwc: Specific cloud ice water content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "15a62baf-4d82-444a-8179-2d5b6ae04739",
   "metadata": {},
   "outputs": [],
   "source": [
    "config_name = os.path.realpath('data_config_6h.yml')\n",
    "\n",
    "with open(config_name, 'r') as stream:\n",
    "    conf = yaml.safe_load(stream)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "77331573-6b69-4a51-83ca-81c25b57654c",
   "metadata": {},
   "outputs": [],
   "source": [
    "year = 2000\n",
    "N_days = 366 if year % 4 == 0 else 365"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "70581b03-5fa6-48b0-bb64-116b0b23e799",
   "metadata": {},
   "outputs": [],
   "source": [
    "compress = zarr.Blosc(cname='zstd', clevel=1, shuffle=zarr.Blosc.SHUFFLE, blocksize=0)\n",
    "\n",
    "\n",
    "chunk_size_4d = dict(chunks=(conf['RDA']['chunk_size_4d']['time'],\n",
    "                                 conf['RDA']['chunk_size_4d']['level'],\n",
    "                                 conf['RDA']['chunk_size_4d']['latitude'],\n",
    "                                 conf['RDA']['chunk_size_4d']['longitude']))\n",
    "\n",
    "dict_encoding = {}\n",
    "\n",
    "for i_var, var in enumerate(conf['RDA']['varname_upper_air']):\n",
    "    dict_encoding[var] = {'compressor': compress, **chunk_size_4d}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5107f5c1-a8e0-461b-8a26-ba94f22ec93f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# increase the file cache size\n",
    "xr.set_options(file_cache_maxsize=500)\n",
    "# lock for safe parallel access\n",
    "netcdf_lock = SerializableLock()\n",
    "\n",
    "# all days within a year\n",
    "start_time = datetime(year, 1, 1, 0, 0)\n",
    "dt_list = [start_time + timedelta(days=i) for i in range(N_days)]\n",
    "\n",
    "# upper-air var names\n",
    "varnames = list(conf['RDA']['varname_upper_air'].values())\n",
    "\n",
    "ds_list = []\n",
    "\n",
    "for i_day, dt in enumerate(dt_list):\n",
    "    # file source info\n",
    "    base_dir = dt.strftime(conf['RDA']['source']['anpl_format'])\n",
    "    dt_pattern = dt.strftime(conf['RDA']['source']['anpl_dt_pattern_format'])\n",
    "\n",
    "    # get upper-air vars\n",
    "    filename_collection = [glob(base_dir + f'*{var}*{dt_pattern}*')[0] for var in varnames]\n",
    "    \n",
    "    if len(filename_collection) != len(varnames):\n",
    "        raise ValueError(f'Year {year}, day {day_idx} has incomplete files')\n",
    "    \n",
    "    # Open with a lock to avoid race conditions when accessing files\n",
    "    ds = xr.open_mfdataset(filename_collection, combine='by_coords', parallel=True, lock=netcdf_lock)\n",
    "\n",
    "    # drop useless var\n",
    "    ds = ds.drop_vars('utc_date', errors='ignore')\n",
    "\n",
    "    # hourly --> 6 hourly\n",
    "    ds = ds.isel(time=slice(0, -1, 6))\n",
    "    \n",
    "    #  chunking\n",
    "    ds = ds.chunk(conf['RDA']['chunk_size_4d'])\n",
    "    ds_list.append(ds)\n",
    "    \n",
    "# concatenate\n",
    "ds_yearly = xr.concat(ds_list, dim='time')\n",
    "\n",
    "# save to zarr\n",
    "base_dir = conf['RDA']['save_loc'] + 'upper_air/' \n",
    "if not os.path.exists(base_dir):\n",
    "    os.makedirs(base_dir)\n",
    "\n",
    "save_name = base_dir + conf['RDA']['prefix'] + '_upper_air_{}.zarr'.format(year)\n",
    "\n",
    "# ds_yearly.to_zarr(save_name, mode='w', consolidated=True, compute=True, encoding=dict_encoding)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2e49d89-5e48-46f7-a2fa-da2382fe9eb6",
   "metadata": {},
   "source": [
    "### check time coords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0f81159f-a814-4afa-81a0-e72b0ac5ff13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for year in range(1979, 2024):\n",
    "\n",
    "#     # save to zarr\n",
    "#     base_dir = conf['RDA']['save_loc'] + 'upper_air/' \n",
    "#     save_name = base_dir + conf['RDA']['prefix'] + '_upper_air_{}.zarr'.format(year)\n",
    "#     ds_year = xr.open_zarr(save_name)\n",
    "    \n",
    "#     time = ds_year['time'].values\n",
    "    \n",
    "#     # Check if the time coordinate is monotonic (increasing)\n",
    "#     is_monotonic = np.all(np.diff(time) > np.timedelta64(0, 'ns'))\n",
    "    \n",
    "#     # Check if the time intervals between consecutive values are equal to 1 hour\n",
    "#     time_diff = np.diff(time)  # Get the differences between consecutive time values\n",
    "#     hourly_gap = np.timedelta64(6, 'h')  # 1 hour in timedelta64 format\n",
    "#     is_hourly_gap = np.all(time_diff == hourly_gap)\n",
    "    \n",
    "#     # Final check if both conditions are satisfied\n",
    "#     is_monotonic_and_hourly = is_monotonic and is_hourly_gap\n",
    "    \n",
    "#     print(\"Is time coordinate monotonic with an hourly gap?\", is_monotonic_and_hourly)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70a15062-1068-4ef3-bfda-843470fbdf96",
   "metadata": {},
   "source": [
    "### Single-level variables"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cf57dbf-a2f6-4057-8356-99bfccb84152",
   "metadata": {},
   "source": [
    "An example of file listing at `/glade/campaign/collections/rda/data/d633000/e5.oper.an.sfc/197901`\n",
    "\n",
    "```\n",
    "e5.oper.an.sfc.128_015_aluvp.ll025sc.1979010100_1979013123.nc  e5.oper.an.sfc.128_167_2t.ll025sc.1979010100_1979013123.nc\n",
    "e5.oper.an.sfc.128_016_aluvd.ll025sc.1979010100_1979013123.nc  e5.oper.an.sfc.128_168_2d.ll025sc.1979010100_1979013123.nc\n",
    "e5.oper.an.sfc.128_017_alnip.ll025sc.1979010100_1979013123.nc  e5.oper.an.sfc.128_170_stl2.ll025sc.1979010100_1979013123.nc\n",
    "e5.oper.an.sfc.128_018_alnid.ll025sc.1979010100_1979013123.nc  e5.oper.an.sfc.128_183_stl3.ll025sc.1979010100_1979013123.nc\n",
    "e5.oper.an.sfc.128_031_ci.ll025sc.1979010100_1979013123.nc     e5.oper.an.sfc.128_186_lcc.ll025sc.1979010100_1979013123.nc\n",
    "e5.oper.an.sfc.128_032_asn.ll025sc.1979010100_1979013123.nc    e5.oper.an.sfc.128_187_mcc.ll025sc.1979010100_1979013123.nc\n",
    "e5.oper.an.sfc.128_033_rsn.ll025sc.1979010100_1979013123.nc    e5.oper.an.sfc.128_188_hcc.ll025sc.1979010100_1979013123.nc\n",
    "e5.oper.an.sfc.128_034_sstk.ll025sc.1979010100_1979013123.nc   e5.oper.an.sfc.128_198_src.ll025sc.1979010100_1979013123.nc\n",
    "e5.oper.an.sfc.128_035_istl1.ll025sc.1979010100_1979013123.nc  e5.oper.an.sfc.128_206_tco3.ll025sc.1979010100_1979013123.nc\n",
    "e5.oper.an.sfc.128_036_istl2.ll025sc.1979010100_1979013123.nc  e5.oper.an.sfc.128_229_iews.ll025sc.1979010100_1979013123.nc\n",
    "e5.oper.an.sfc.128_037_istl3.ll025sc.1979010100_1979013123.nc  e5.oper.an.sfc.128_230_inss.ll025sc.1979010100_1979013123.nc\n",
    "e5.oper.an.sfc.128_038_istl4.ll025sc.1979010100_1979013123.nc  e5.oper.an.sfc.128_231_ishf.ll025sc.1979010100_1979013123.nc\n",
    "e5.oper.an.sfc.128_039_swvl1.ll025sc.1979010100_1979013123.nc  e5.oper.an.sfc.128_232_ie.ll025sc.1979010100_1979013123.nc\n",
    "e5.oper.an.sfc.128_040_swvl2.ll025sc.1979010100_1979013123.nc  e5.oper.an.sfc.128_235_skt.ll025sc.1979010100_1979013123.nc\n",
    "e5.oper.an.sfc.128_041_swvl3.ll025sc.1979010100_1979013123.nc  e5.oper.an.sfc.128_236_stl4.ll025sc.1979010100_1979013123.nc\n",
    "e5.oper.an.sfc.128_042_swvl4.ll025sc.1979010100_1979013123.nc  e5.oper.an.sfc.128_238_tsn.ll025sc.1979010100_1979013123.nc\n",
    "e5.oper.an.sfc.128_059_cape.ll025sc.1979010100_1979013123.nc   e5.oper.an.sfc.128_243_fal.ll025sc.1979010100_1979013123.nc\n",
    "e5.oper.an.sfc.128_066_lailv.ll025sc.1979010100_1979013123.nc  e5.oper.an.sfc.128_244_fsr.ll025sc.1979010100_1979013123.nc\n",
    "e5.oper.an.sfc.128_067_laihv.ll025sc.1979010100_1979013123.nc  e5.oper.an.sfc.128_245_flsr.ll025sc.1979010100_1979013123.nc\n",
    "e5.oper.an.sfc.128_078_tclw.ll025sc.1979010100_1979013123.nc   e5.oper.an.sfc.228_008_lmlt.ll025sc.1979010100_1979013123.nc\n",
    "e5.oper.an.sfc.128_079_tciw.ll025sc.1979010100_1979013123.nc   e5.oper.an.sfc.228_009_lmld.ll025sc.1979010100_1979013123.nc\n",
    "e5.oper.an.sfc.128_134_sp.ll025sc.1979010100_1979013123.nc     e5.oper.an.sfc.228_010_lblt.ll025sc.1979010100_1979013123.nc\n",
    "e5.oper.an.sfc.128_136_tcw.ll025sc.1979010100_1979013123.nc    e5.oper.an.sfc.228_011_ltlt.ll025sc.1979010100_1979013123.nc\n",
    "e5.oper.an.sfc.128_137_tcwv.ll025sc.1979010100_1979013123.nc   e5.oper.an.sfc.228_012_lshf.ll025sc.1979010100_1979013123.nc\n",
    "e5.oper.an.sfc.128_139_stl1.ll025sc.1979010100_1979013123.nc   e5.oper.an.sfc.228_013_lict.ll025sc.1979010100_1979013123.nc\n",
    "e5.oper.an.sfc.128_141_sd.ll025sc.1979010100_1979013123.nc     e5.oper.an.sfc.228_014_licd.ll025sc.1979010100_1979013123.nc\n",
    "e5.oper.an.sfc.128_148_chnk.ll025sc.1979010100_1979013123.nc   e5.oper.an.sfc.228_089_tcrw.ll025sc.1979010100_1979013123.nc\n",
    "e5.oper.an.sfc.128_151_msl.ll025sc.1979010100_1979013123.nc    e5.oper.an.sfc.228_090_tcsw.ll025sc.1979010100_1979013123.nc\n",
    "e5.oper.an.sfc.128_159_blh.ll025sc.1979010100_1979013123.nc    e5.oper.an.sfc.228_131_u10n.ll025sc.1979010100_1979013123.nc\n",
    "e5.oper.an.sfc.128_164_tcc.ll025sc.1979010100_1979013123.nc    e5.oper.an.sfc.228_132_v10n.ll025sc.1979010100_1979013123.nc\n",
    "e5.oper.an.sfc.128_165_10u.ll025sc.1979010100_1979013123.nc    e5.oper.an.sfc.228_246_100u.ll025sc.1979010100_1979013123.nc\n",
    "e5.oper.an.sfc.128_166_10v.ll025sc.1979010100_1979013123.nc    e5.oper.an.sfc.228_247_100v.ll025sc.1979010100_1979013123.nc\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bcec2c2f-f769-4a5c-a70e-fca40d672c11",
   "metadata": {},
   "outputs": [],
   "source": [
    "year = 2000\n",
    "N_months = 12\n",
    "\n",
    "config_name = os.path.realpath('data_config_6h.yml')\n",
    "\n",
    "with open(config_name, 'r') as stream:\n",
    "    conf = yaml.safe_load(stream)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a8d07006-5a2a-4976-aafc-124c85555333",
   "metadata": {},
   "outputs": [],
   "source": [
    "compress = zarr.Blosc(cname='zstd', clevel=1, shuffle=zarr.Blosc.SHUFFLE, blocksize=0)\n",
    "\n",
    "\n",
    "chunk_size_3d = dict(chunks=(conf['RDA']['chunk_size_3d']['time'],\n",
    "                             conf['RDA']['chunk_size_3d']['latitude'],\n",
    "                             conf['RDA']['chunk_size_3d']['longitude']))\n",
    "\n",
    "dict_encoding = {}\n",
    "\n",
    "for i_var, var in enumerate(conf['RDA']['varname_single']):\n",
    "    dict_encoding[var] = {'compressor': compress, **chunk_size_3d}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "043142a3-c181-4d89-bd3f-8c9f65769887",
   "metadata": {},
   "outputs": [],
   "source": [
    "# increase the file cache size\n",
    "xr.set_options(file_cache_maxsize=500)\n",
    "# lock for safe parallel access\n",
    "netcdf_lock = SerializableLock()\n",
    "\n",
    "# all days within a year\n",
    "start_time = datetime(year, 1, 1, 0, 0)\n",
    "dt_list = [start_time + relativedelta(months=i) for i in range(N_months)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1695721b-6009-4917-9579-7cd089926a26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# var names\n",
    "varnames = list(conf['RDA']['varname_single'].values())\n",
    "\n",
    "ds_list = []\n",
    "\n",
    "for i_mon, dt in enumerate(dt_list):\n",
    "    # file source info\n",
    "    base_dir = dt.strftime(conf['RDA']['source']['ansfc_format'])\n",
    "\n",
    "    first_day = datetime(year, dt.month, 1)\n",
    "    last_day = datetime(year, dt.month, calendar.monthrange(year, dt.month)[1])\n",
    "    \n",
    "    dt_pattern = dt.strftime(conf['RDA']['source']['ansfc_dt_pattern_format'])\n",
    "    dt_pattern = dt_pattern.format(first_day.day, last_day.day)\n",
    "    \n",
    "    # get upper-air vars\n",
    "    filename_collection = [glob(base_dir + f'*{var}*{dt_pattern}*')[0] for var in varnames]\n",
    "    \n",
    "    if len(filename_collection) != len(varnames):\n",
    "        raise ValueError(f'Year {year}, day {day_idx} has incomplete files')\n",
    "    \n",
    "    # Open with a lock to avoid race conditions when accessing files\n",
    "    ds = xr.open_mfdataset(filename_collection, combine='by_coords', parallel=True, lock=netcdf_lock)\n",
    "\n",
    "    # drop useless var\n",
    "    ds = ds.drop_vars('utc_date', errors='ignore')\n",
    "\n",
    "    # hourly --> 6 hourly\n",
    "    ds = ds.isel(time=slice(0, -1, 6))\n",
    "    \n",
    "    #  chunking\n",
    "    ds = ds.chunk(conf['RDA']['chunk_size_3d'])\n",
    "    ds_list.append(ds)\n",
    "    \n",
    "# concatenate\n",
    "ds_yearly = xr.concat(ds_list, dim='time')\n",
    "\n",
    "# save to zarr\n",
    "base_dir = conf['RDA']['save_loc'] + 'surf/' \n",
    "if not os.path.exists(base_dir):\n",
    "    os.makedirs(base_dir)\n",
    "\n",
    "save_name = base_dir + conf['RDA']['prefix'] + '_surf_{}.zarr'.format(year)\n",
    "\n",
    "# ds_yearly.to_zarr(save_name, mode='w', consolidated=True, compute=True, encoding=dict_encoding)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba5bff1d-7b53-42a6-a134-651d1c5d41d7",
   "metadata": {},
   "source": [
    "### check time coords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "95b7bfbc-5626-40c3-98b6-69ad74860ffd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for year in range(1979, 2024):\n",
    "\n",
    "#     # save to zarr\n",
    "#     base_dir = conf['RDA']['save_loc'] + 'surf/' \n",
    "#     save_name = base_dir + conf['RDA']['prefix'] + '_surf_{}.zarr'.format(year)\n",
    "    \n",
    "#     time = ds_year['time'].values\n",
    "    \n",
    "#     # Check if the time coordinate is monotonic (increasing)\n",
    "#     is_monotonic = np.all(np.diff(time) > np.timedelta64(0, 'ns'))\n",
    "    \n",
    "#     # Check if the time intervals between consecutive values are equal to 1 hour\n",
    "#     time_diff = np.diff(time)  # Get the differences between consecutive time values\n",
    "#     hourly_gap = np.timedelta64(6, 'h')  # 1 hour in timedelta64 format\n",
    "#     is_hourly_gap = np.all(time_diff == hourly_gap)\n",
    "    \n",
    "#     # Final check if both conditions are satisfied\n",
    "#     is_monotonic_and_hourly = is_monotonic and is_hourly_gap\n",
    "    \n",
    "#     print(\"Is time coordinate monotonic with an hourly gap?\", is_monotonic_and_hourly)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36abe181-24fb-4e75-b0a3-f2717eb721e3",
   "metadata": {},
   "source": [
    "## Single-level accumulative variables\n",
    "\n",
    "**RDA**\n",
    "\n",
    "* Example file listing: `/glade/campaign/collections/rda/data/d633000/e5.oper.fc.sfc.accumu/197901`\n",
    "\n",
    "**ARCO**\n",
    "\n",
    "* Hourly data from `gs://gcp-public-data-arco-era5/ar/full_37-1h-0p25deg-chunk-1.zarr-v3`\n",
    "* Accumulate hourly to 6 hourly: `xarray.resample(time='6h').sum()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c90f4e20-8ae2-4f47-a9ff-9ed2b3ab6a7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "year = 1979\n",
    "N_days = 366 if year % 4 == 0 else 365\n",
    "\n",
    "config_name = os.path.realpath('data_config_6h.yml')\n",
    "\n",
    "with open(config_name, 'r') as stream:\n",
    "    conf = yaml.safe_load(stream)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c7b66dcb-473d-4b75-85db-db2fd4749d44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save to zarr\n",
    "base_dir = conf['ARCO']['save_loc'] + 'accum/' \n",
    "if not os.path.exists(base_dir):\n",
    "    os.makedirs(base_dir)\n",
    "\n",
    "compress = zarr.Blosc(cname='zstd', clevel=1, shuffle=zarr.Blosc.SHUFFLE, blocksize=0)\n",
    "\n",
    "\n",
    "chunk_size_3d = dict(chunks=(conf['ARCO']['chunk_size_3d']['time'],\n",
    "                             conf['ARCO']['chunk_size_3d']['latitude'],\n",
    "                             conf['ARCO']['chunk_size_3d']['longitude']))\n",
    "\n",
    "dict_encoding = {}\n",
    "\n",
    "for i_var, var in enumerate(conf['ARCO']['varname_accum']):\n",
    "    dict_encoding[var] = {'compressor': compress, **chunk_size_3d}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "73b9bcbe-09c8-40eb-9e24-810a6bec4211",
   "metadata": {},
   "outputs": [],
   "source": [
    "ERA5_1h = xr.open_zarr(\n",
    "    \"gs://gcp-public-data-arco-era5/ar/full_37-1h-0p25deg-chunk-1.zarr-v3\",\n",
    "    chunks=None,\n",
    "    storage_options=dict(token='anon'),)\n",
    "\n",
    "time_start = '{}-12-31T00'.format(year-1) # hourly accum var needs one extra day to accum on 6 hrs\n",
    "time_start_save = '{}-01-01T00'.format(year)\n",
    "time_end = '{}-01-03T23'.format(year)\n",
    "#time_end = '{}-12-31T23'.format(year)\n",
    "ERA5_1h_yearly = ERA5_1h.sel(time=slice(time_start, time_end))\n",
    "\n",
    "variables_levels = {}\n",
    "for varname in conf['ARCO']['varname_accum']:\n",
    "    variables_levels[varname] = None\n",
    "\n",
    "ERA5_1h_save = vu.ds_subset_everything(ERA5_1h_yearly, variables_levels)\n",
    "\n",
    "ERA5_1h_shifted = ERA5_1h_save.shift(time=-1)\n",
    "ERA5_6h = ERA5_1h_shifted.resample(time='6h').sum()\n",
    "ERA5_6h['time'] = ERA5_6h['time'] + pd.Timedelta(hours=6)\n",
    "\n",
    "ERA5_6h_save = ERA5_6h.sel(time=slice(time_start_save, time_end))\n",
    "\n",
    "ERA5_6h_save = ERA5_6h_save.chunk(conf['ARCO']['chunk_size_3d'])\n",
    "save_name = base_dir + conf['ARCO']['prefix'] + '_accum_{}.zarr'.format(year)\n",
    "# ERA5_6h_save.to_zarr(save_name, mode=\"w\", consolidated=True, compute=True, encoding=dict_encoding)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7049fd06-adad-42b0-ab6d-5348068f15e0",
   "metadata": {},
   "source": [
    "**Comparing accumulated hourly to the old directly available 6 hourly data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fed5eb54-ccf6-4629-aa61-2299193d370f",
   "metadata": {},
   "outputs": [],
   "source": [
    "ERA5_6h = xr.open_zarr(\n",
    "    \"gs://gcp-public-data-arco-era5/ar/1959-2022-6h-1440x721.zarr\",\n",
    "    chunks=None,\n",
    "    storage_options=dict(token='anon'),)\n",
    "\n",
    "tp_6h_ref = ERA5_6h['total_precipitation_6hr']\n",
    "tp_6h_ref = tp_6h_ref.sel(time=slice(time_start_save, time_end))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "95ef49e2-394c-4691-9fb9-a4a21220daa8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n",
      "0.0\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "for ind_check in range(3):\n",
    "    diff = np.sum(np.array(ERA5_6h_save['total_precipitation'].isel(time=ind_check)) - \\\n",
    "                  np.array(tp_6h_ref.isel(time=ind_check)))\n",
    "    print(diff)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5144d188-0343-451e-b563-f0a61c6d0d74",
   "metadata": {},
   "source": [
    "### Static variables"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a32294a-a8b2-4057-9bab-13151a06ddff",
   "metadata": {},
   "source": [
    "**ARCO**\n",
    "\n",
    "* Hourly data from `gs://gcp-public-data-arco-era5/ar/full_37-1h-0p25deg-chunk-1.zarr-v3`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1109ac91-8eb0-4bc2-985a-d4a2617f9153",
   "metadata": {},
   "outputs": [],
   "source": [
    "config_name = os.path.realpath('data_config_6h.yml')\n",
    "\n",
    "with open(config_name, 'r') as stream:\n",
    "    conf = yaml.safe_load(stream)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "59f502d3-13db-41a0-bee1-d53ca68e2077",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save to zarr\n",
    "base_dir = conf['ARCO']['save_loc'] + 'static/' \n",
    "if not os.path.exists(base_dir):\n",
    "    os.makedirs(base_dir)\n",
    "\n",
    "compress = zarr.Blosc(cname='zstd', clevel=1, shuffle=zarr.Blosc.SHUFFLE, blocksize=0)\n",
    "\n",
    "dict_encoding = {}\n",
    "\n",
    "for i_var, var in enumerate(conf['ARCO']['varname_static']):\n",
    "    dict_encoding[var] = {'compressor': compress}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b49eed24-b552-45b0-8a60-84b1c390c0c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "ERA5_1h = xr.open_zarr(\n",
    "    \"gs://gcp-public-data-arco-era5/ar/full_37-1h-0p25deg-chunk-1.zarr-v3\",\n",
    "    chunks=None,\n",
    "    storage_options=dict(token='anon'),)\n",
    "\n",
    "ERA5_1h_slice = ERA5_1h.sel(time='2000-01-01T00')\n",
    "\n",
    "variables_levels = {}\n",
    "for varname in conf['ARCO']['varname_static']:\n",
    "    variables_levels[varname] = None\n",
    "\n",
    "ERA5_static = vu.ds_subset_everything(ERA5_1h_slice, variables_levels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9739a7a1-1db6-43a5-8abe-91cb8562b887",
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalize 'geopotential_at_surface'\n",
    "mean_val = float(ERA5_static['geopotential_at_surface'].mean(skipna=False))\n",
    "std_val = float(ERA5_static['geopotential_at_surface'].std(skipna=False))\n",
    "ERA5_static['z_norm'] = (ERA5_static['geopotential_at_surface'] - mean_val)/std_val\n",
    "\n",
    "# normalize soil type\n",
    "ERA5_static['soil_type'] = ERA5_static['soil_type'] / 7\n",
    "\n",
    "# fix coordiante names\n",
    "ds_example = xr.open_zarr(\n",
    "    '/glade/derecho/scratch/ksha/CREDIT_data/ERA5_plevel_base/all_in_one/ERA5_plevel_6h_1979.zarr')\n",
    "ERA5_static['latitude'] = ds_example['latitude']\n",
    "ERA5_static['longitude'] = ds_example['longitude']\n",
    "ERA5_static = ERA5_static.drop_vars('time')\n",
    "\n",
    "save_name = base_dir + conf['ARCO']['prefix'] + '_static.zarr'\n",
    "# ERA5_static.to_zarr(save_name, mode=\"w\", consolidated=True, compute=True, encoding=dict_encoding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4ed8872c-e329-40df-87c4-b5aa9d975a84",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/glade/derecho/scratch/ksha/CREDIT_data/ERA5_plevel_base/static/ERA5_plevel_6h_static.zarr'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "save_name"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6be7b8e9-de38-4e67-bca9-b78841cb6542",
   "metadata": {},
   "source": [
    "**Add coslat variable**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "50da8fd4-5ba4-4e27-8398-7b2478e52296",
   "metadata": {},
   "outputs": [],
   "source": [
    "# base_dir = conf['ARCO']['save_loc'] + 'static/' \n",
    "# save_name = base_dir + conf['ARCO']['prefix'] + '_static.zarr'\n",
    "# ERA5_static = xr.open_zarr(save_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "606cd8cb-4c57-4414-97fb-10a94ecb4045",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ERA5_static['geopotential_at_surface']\n",
    "# ERA5_static['z_norm']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be4daf6c-03b8-4074-838d-970e656d2e66",
   "metadata": {},
   "source": [
    "**Add mean and std to their files**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "88a603dc-2299-43ce-b86a-8b862d8c5332",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mean_path = conf['ARCO']['save_loc'] + 'mean_std/mean_6h_1979_2019_13lev_0.25deg.nc'\n",
    "# std_path = conf['ARCO']['save_loc'] + 'mean_std/std_residual_6h_1979_2019_13lev_0.25deg.nc'\n",
    "\n",
    "# ds_mean = xr.open_dataset(mean_path)\n",
    "# ds_mean['z_norm'] = mean_val\n",
    "\n",
    "# ds_std = xr.open_dataset(std_path)\n",
    "# ds_std['z_norm'] = std_val\n",
    "\n",
    "# ds_mean.to_netcdf(mean_path, mode=\"w\")\n",
    "# ds_std.to_netcdf(std_path, mode=\"w\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cd27bfa-886a-4c98-96be-6b450ead005d",
   "metadata": {},
   "source": [
    "## Others\n",
    "\n",
    "### Total precipitation from RDA\n",
    "\n",
    "\n",
    "```python\n",
    "xr_ARCO = xr.open_zarr('/glade/derecho/scratch/ksha/CREDIT_data/ERA5_plevel_base/test_data/surf_test.zarr')\n",
    "tp_ARCO = xr_ARCO['total_precipitation']\n",
    "\n",
    "base_dir = '/glade/campaign/collections/rda/data/d633000/e5.oper.fc.sfc.accumu/197901/'\n",
    "xr_RDA_CP = xr.open_dataset(base_dir+'e5.oper.fc.sfc.accumu.128_143_cp.ll025sc.1979010106_1979011606.nc')\n",
    "xr_RDA_LP = xr.open_dataset(base_dir+'e5.oper.fc.sfc.accumu.128_142_lsp.ll025sc.1979010106_1979011606.nc')\n",
    "\n",
    "xr_RDA_CP = xr_RDA_CP.drop_vars('utc_date', errors='ignore')\n",
    "xr_RDA_CP = xr_RDA_CP.rename({'CP': 'TP'})\n",
    "xr_RDA_LP = xr_RDA_LP.drop_vars('utc_date', errors='ignore')\n",
    "xr_RDA_LP = xr_RDA_LP.rename({'LSP': 'TP'})\n",
    "\n",
    "da = xr_RDA_CP + xr_RDA_LP\n",
    "\n",
    "time_deltas = pd.to_timedelta(da[\"forecast_hour\"].values, unit=\"h\")\n",
    "new_times = np.add.outer(da[\"forecast_initial_time\"].values, time_deltas)\n",
    "new_times = new_times.flatten()\n",
    "\n",
    "da_an = da.stack(time=(\"forecast_initial_time\", \"forecast_hour\"))\n",
    "da_an = da_an.drop_vars(['forecast_hour', 'forecast_initial_time', 'time'])\n",
    "da_an = da_an.assign_coords(time=new_times)\n",
    "\n",
    "for i_hour in range(10):\n",
    "    # i + 7 becuase ini_time = 06Z, fcst_lead_time starts from 01 hr\n",
    "    tp_ARCO_np = np.array(tp_ARCO.isel(time=i_hour+7))\n",
    "    da_np = np.array(da_an['TP'].isel(time=i_hour))\n",
    "    print(np.sum(np.abs(tp_ARCO_np - da_np)))\n",
    "\n",
    "# ARCO vs. RDA\n",
    "data_var = da['TP']\n",
    "tp_RDA = data_var.isel(forecast_initial_time=0)\n",
    "tp_RDA_np = np.array(tp_RDA)\n",
    "tp_ARCO_np = np.array(tp_ARCO.isel(time=slice(7, 7+12)))\n",
    "np.sum(np.abs(tp_ARCO_np[3, ...] - tp_RDA_np[3, ...]))\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82eb0996-4d21-43cc-9a98-4cfc1f4ea742",
   "metadata": {},
   "source": [
    "### Combine Q components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a849486a-0222-4a54-92ab-892d9729f561",
   "metadata": {},
   "outputs": [],
   "source": [
    "config_name = os.path.realpath('data_config_6h.yml')\n",
    "\n",
    "with open(config_name, 'r') as stream:\n",
    "    conf = yaml.safe_load(stream)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4bf08fd4-bbe8-427c-8a06-def5d7320492",
   "metadata": {},
   "outputs": [],
   "source": [
    "year = 1989\n",
    "\n",
    "chunk_size_4d = dict(chunks=(conf['zarr_opt']['chunk_size_4d']['time'],\n",
    "                             conf['zarr_opt']['chunk_size_4d']['level'],\n",
    "                             conf['zarr_opt']['chunk_size_4d']['latitude'],\n",
    "                             conf['zarr_opt']['chunk_size_4d']['longitude']))\n",
    "\n",
    "base_dir = conf['zarr_opt']['save_loc']\n",
    "zarr_name_upper = sorted(glob(base_dir+'upper_air/ERA5_plevel_6h_upper_air_*.zarr'))\n",
    "zarr_name_cloud = sorted(glob(base_dir+'cloud/*.zarr'))\n",
    "\n",
    "fn_upper = [fn for fn in zarr_name_upper if str(year) in fn][0]\n",
    "fn_cloud = [fn for fn in zarr_name_cloud if str(year) in fn][0]\n",
    "\n",
    "variables_levels = {}\n",
    "variables_levels['Q'] = None\n",
    "\n",
    "ds_upper = xr.open_zarr(fn_upper).chunk(conf['zarr_opt']['chunk_size_4d'])\n",
    "ds_upper = vu.ds_subset_everything(ds_upper, variables_levels)\n",
    "\n",
    "ds_cloud = xr.open_zarr(fn_cloud).chunk(conf['zarr_opt']['chunk_size_4d'])\n",
    "\n",
    "# ds_upper['Q'] = ds_upper['Q'] + ds_cloud['CLWC'] + ds_cloud['CRWC']\n",
    "# + ds_cloud['CSWC'] +  ds_cloud['CIWC']\n",
    "\n",
    "# ds_upper = ds_upper.rename({'Q': 'specific_total_water'})\n",
    "\n",
    "dict_encoding = {}\n",
    "compress = zarr.Blosc(cname='zstd', clevel=1, shuffle=zarr.Blosc.SHUFFLE, blocksize=0)\n",
    "dict_encoding['specific_total_water'] = {'compressor': compress, **chunk_size_4d}\n",
    "\n",
    "save_name = base_dir+'upper_air/ERA5_plevel_6h_Q_{}.zarr'.format(year)\n",
    "# ds_upper.to_zarr(save_name, mode='w', consolidated=True, compute=True, encoding=dict_encoding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "eabb339f-c8bb-4e32-8e55-2d5741084c0d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/glade/derecho/scratch/ksha/CREDIT_data/ERA5_plevel_base/'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "245f1575-6fee-4eb3-8d5b-147471d4b1ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q = np.array(ds_upper['Q'].isel(time=999))\n",
    "CIWC = np.array(ds_cloud['CIWC'].isel(time=999))\n",
    "CLWC = np.array(ds_cloud['CLWC'].isel(time=999))\n",
    "CRWC = np.array(ds_cloud['CRWC'].isel(time=999))\n",
    "CSWC = np.array(ds_cloud['CSWC'].isel(time=999))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "5dbe13c9-1bcf-455c-ac8b-720ec6bc66df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.005934408 0.019964522\n",
      "2.2040711e-05 0.0011463165\n",
      "2.2253564e-06 0.0015803277\n"
     ]
    }
   ],
   "source": [
    "i_level = -5\n",
    "print(Q[i_level, ...].mean(), Q[i_level, ...].max())\n",
    "print(CLWC[i_level, ...].mean(), CLWC[i_level, ...].max()) # 225 hPa level 15\n",
    "print(CRWC[i_level, ...].mean(), CRWC[i_level, ...].max()) # 300 hPa level 17"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "5fa91714-1a66-4e8d-ae78-5de67c56f951",
   "metadata": {},
   "outputs": [],
   "source": [
    "levels = ds_upper['level'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b8bd5e5-8eed-4e40-9606-cbf204127d6e",
   "metadata": {},
   "source": [
    "### Combine all in one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e0e59efa-8c28-493a-b1a4-4bc9cdc150f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "year = 1979\n",
    "base_dir = conf['zarr_opt']['save_loc']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d86c108a-e46e-4949-882f-fc9acd251592",
   "metadata": {},
   "outputs": [],
   "source": [
    "zarr_name_surf = base_dir+'surf/ERA5_plevel_6h_surf_{}.zarr'\n",
    "zarr_name_surf_extra = base_dir+'surf/ERA5_plevel_6h_surf_extend_{}.zarr'\n",
    "zarr_name_accum = base_dir+'accum/ERA5_plevel_6h_accum_{}.zarr'\n",
    "zarr_name_forcing = base_dir+'forcing/ERA5_plevel_6h_forcing_{}.zarr'\n",
    "zarr_name_upper = base_dir+'upper_subset/ERA5_subset_6h_upper_air_{}.zarr'\n",
    "zarr_name_upper_full = base_dir+'upper_air/ERA5_plevel_6h_upper_air_{}.zarr'\n",
    "zarr_name_upper_Q = base_dir+'upper_air/ERA5_plevel_6h_Q_{}.zarr'\n",
    "zarr_name_Q = base_dir+'upper_subset/ERA5_subset_6h_Q_{}.zarr'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "360d458b-1ed8-48b6-a850-98a47338be94",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_surf = xr.open_zarr(zarr_name_surf.format(year))\n",
    "ds_surf_extra = xr.open_zarr(zarr_name_surf_extra.format(year))\n",
    "ds_accum = xr.open_zarr(zarr_name_accum.format(year))\n",
    "ds_forcing = xr.open_zarr(zarr_name_forcing.format(year))\n",
    "ds_upper = xr.open_zarr(zarr_name_upper.format(year))\n",
    "ds_upper_full = xr.open_zarr(zarr_name_upper_full.format(year))\n",
    "ds_upper_Q = xr.open_zarr(zarr_name_upper_Q.format(year))\n",
    "ds_Q = xr.open_zarr(zarr_name_Q.format(year))\n",
    "\n",
    "ds_500hPa = xr.merge([ds_upper_full.isel(level=21), ds_upper_Q.isel(level=21)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "0545688d-d97e-4f98-8406-711582ca483b",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_500hPa = ds_500hPa.rename({'T': 'T500', \n",
    "                              'U': 'U500', \n",
    "                              'V': 'V500', \n",
    "                              'Z': 'Z500', \n",
    "                              'Q': 'Q500', \n",
    "                              'specific_total_water': 'specific_total_water_500'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "bcda708f-20ae-4d6d-92f1-cf4e849234b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# combining land-sea mask and sea-ice cover\n",
    "\n",
    "ds_static = xr.open_zarr(base_dir+'static/ERA5_plevel_6h_static.zarr')\n",
    "land_sea_mask = ds_static['land_sea_mask']\n",
    "sea_ice_cover = ds_surf_extra['CI']\n",
    "\n",
    "land_sea_mask_expanded = land_sea_mask.broadcast_like(sea_ice_cover)\n",
    "land_sea_CI_mask = xr.where(\n",
    "    (land_sea_mask_expanded == 0) & (sea_ice_cover > 0),\n",
    "    -sea_ice_cover,\n",
    "    land_sea_mask_expanded\n",
    ")\n",
    "\n",
    "land_sea_CI_mask.name = 'land_sea_CI_mask'\n",
    "ds_mask = land_sea_CI_mask.to_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "2cb7b444-7b7e-4eb9-b30c-d50fd719ac40",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_merge = xr.merge([ds_surf, ds_accum, ds_forcing, ds_upper, ds_Q, ds_mask, ds_500hPa])\n",
    "ds_merge = ds_merge.drop_vars('SSTK')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "f2023472-b4df-4347-96c2-d4764b3cc3f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "varnames = list(ds_merge.keys())\n",
    "varname_4D = ['U', 'V', 'T', 'Z', 'Q', 'specific_total_water']\n",
    "\n",
    "for i_var, var in enumerate(varnames):\n",
    "    if var in varname_4D:\n",
    "        ds_merge[var] = ds_merge[var].chunk(conf['zarr_opt']['chunk_size_4d'])\n",
    "    else:\n",
    "        ds_merge[var] = ds_merge[var].chunk(conf['zarr_opt']['chunk_size_3d'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "2f2601c3-a8f5-49ec-86a3-b8d7401b2168",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========================================================================== #\n",
    "# zarr encodings\n",
    "dict_encoding = {}\n",
    "\n",
    "chunk_size_3d = dict(chunks=(conf['zarr_opt']['chunk_size_3d']['time'],\n",
    "                             conf['zarr_opt']['chunk_size_3d']['latitude'],\n",
    "                             conf['zarr_opt']['chunk_size_3d']['longitude']))\n",
    "\n",
    "chunk_size_4d = dict(chunks=(conf['zarr_opt']['chunk_size_4d']['time'],\n",
    "                             conf['zarr_opt']['chunk_size_4d']['level'],\n",
    "                             conf['zarr_opt']['chunk_size_4d']['latitude'],\n",
    "                             conf['zarr_opt']['chunk_size_4d']['longitude']))\n",
    "\n",
    "compress = zarr.Blosc(cname='zstd', clevel=1, shuffle=zarr.Blosc.SHUFFLE, blocksize=0)\n",
    "\n",
    "for i_var, var in enumerate(varnames):\n",
    "    if var in varname_4D:\n",
    "        dict_encoding[var] = {'compressor': compress, **chunk_size_4d}\n",
    "    else:\n",
    "        dict_encoding[var] = {'compressor': compress, **chunk_size_3d}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "f282cb21-a16d-48af-abb9-93c7b439ca20",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_name = base_dir+'all_in_one/ERA5_plevel_6h_{}.zarr'.format(year)\n",
    "# ds_merge.to_zarr(save_name, mode='w', consolidated=True, compute=True, encoding=dict_encoding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cf63006-ae8b-4fb3-8246-f71c38b86bdf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b335b255-5aad-44a0-a645-fb29d9fdd858",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
